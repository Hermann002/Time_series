{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribution normale et la distribution binomiale sont deux types de distributions statistiques, mais elles sont utilisées dans des contextes différents et ont des propriétés distinctes. Voici les principales différences :\n",
    "1. Type de données\n",
    "\n",
    "    Distribution Binomiale :\n",
    "        Données discrètes : La distribution binomiale concerne des résultats discrets (comme le nombre de succès dans un nombre fixe d'essais). Par exemple, le nombre de \"faces\" obtenues après avoir lancé une pièce de monnaie 10 fois.\n",
    "        Nombre d'essais fixe : Il y a un nombre fixe d'essais, et chaque essai peut aboutir à un succès ou un échec.\n",
    "    Distribution Normale :\n",
    "        Données continues : La distribution normale s'applique aux variables continues, c'est-à-dire des valeurs qui peuvent prendre n'importe quelle valeur sur une plage infinie. Par exemple, la taille des individus dans une population.\n",
    "        Pas de nombre d'essais fixe : Elle n'est pas liée à un nombre fixe d'essais ou à des résultats discrets.\n",
    "\n",
    "2. Forme de la distribution\n",
    "\n",
    "    Distribution Binomiale :\n",
    "        La forme de la distribution binomiale dépend du nombre d'essais (n) et de la probabilité de succès (p). Pour un petit nombre d'essais, la distribution peut être asymétrique. Si le nombre d'essais est élevé et que p=0.5p=0.5, elle commence à ressembler à une distribution normale, mais elle reste discrète (avec des valeurs uniquement entières).\n",
    "\n",
    "    Distribution Normale :\n",
    "        La distribution normale a une forme de \"cloche\" symétrique. Elle est caractérisée par sa moyenne (μ) et son écart-type (σ), et décrit des données qui sont symétriquement réparties autour de la moyenne, avec des queues qui s'étendent à l'infini des deux côtés.\n",
    "\n",
    "3. Utilisation\n",
    "\n",
    "    Distribution Binomiale :\n",
    "        Utilisée pour modéliser des expériences ou des processus où il y a un nombre fixe d'essais indépendants, chacun ayant deux résultats possibles (succès/échec).\n",
    "        Exemples : Nombre de succès lors de lancements de pièces, nombre de patients guéris après un traitement, etc.\n",
    "\n",
    "    Distribution Normale :\n",
    "        Utilisée pour modéliser des phénomènes naturels ou des données continues où les valeurs se concentrent autour d'une moyenne et s'étalent de façon symétrique de part et d'autre.\n",
    "        Exemples : Taille, poids, scores de tests, erreurs de mesure, etc.\n",
    "\n",
    "4. Paramètres\n",
    "\n",
    "    Distribution Binomiale :\n",
    "        Paramètres : Nombre d'essais nn et probabilité de succès pp.\n",
    "    Distribution Normale :\n",
    "        Paramètres : Moyenne μμ et écart-type σσ.\n",
    "\n",
    "5. Aires sous la courbe\n",
    "\n",
    "    Distribution Binomiale :\n",
    "        Les probabilités sont représentées par des barres, car la distribution est discrète. L'aire sous chaque barre correspond à la probabilité d'un nombre exact de succès.\n",
    "\n",
    "    Distribution Normale :\n",
    "        La courbe est lisse et continue. L'aire sous la courbe entre deux points donne la probabilité qu'une valeur se trouve dans cet intervalle.\n",
    "\n",
    "Résumé\n",
    "\n",
    "    Distribution Binomiale : Utilisée pour des situations avec des résultats discrets et un nombre fixe d'essais.\n",
    "    Distribution Normale : Utilisée pour modéliser des données continues qui se répartissent symétriquement autour d'une moyenne.\n",
    "\n",
    "Ces distributions sont liées : avec un grand nombre d'essais, la distribution binomiale peut parfois être approximée par une distribution normale (c'est le théorème central limite qui explique cela).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilité que la valeur soit entre 70 et 100 : 0.6859110124631886\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "# Paramètres de la distribution normale\n",
    "mu = 80\n",
    "sigma = 14\n",
    "\n",
    "# Valeurs limites\n",
    "lower_bound = 70\n",
    "upper_bound = 100\n",
    "\n",
    "# Calcul des probabilités cumulatives\n",
    "p_lower = norm.cdf(lower_bound, loc=mu, scale=sigma)\n",
    "p_upper = norm.cdf(upper_bound, loc=mu, scale=sigma)\n",
    "\n",
    "# Probabilité que la valeur soit entre 70 et 100\n",
    "probability = p_upper - p_lower\n",
    "\n",
    "print(\"Probabilité que la valeur soit entre 70 et 100 :\", probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour maximiser votre apprentissage du machine learning en appliquant la loi de Pareto (principe 80/20), voici les 20 % des sujets qui vous apporteront 80 % de la compréhension et des compétences nécessaires pour commencer :\n",
    "1. Les bases des statistiques et des probabilités\n",
    "\n",
    "    Importance : Les concepts de base en statistiques (comme la moyenne, la variance, la distribution) et en probabilités sont fondamentaux pour comprendre les algorithmes de machine learning.\n",
    "    Pourquoi : Ils vous aideront à comprendre les distributions de données, l'inférence statistique, et les bases des modèles probabilistes.\n",
    "\n",
    "2. Algèbre linéaire et calcul matriciel\n",
    "\n",
    "    Importance : Connaître les vecteurs, matrices, et opérations matricielles est crucial pour comprendre des algorithmes comme la régression linéaire et les réseaux de neurones.\n",
    "    Pourquoi : Les données sont souvent représentées sous forme de matrices, et de nombreux algorithmes utilisent des opérations matricielles.\n",
    "\n",
    "3. Régression linéaire\n",
    "\n",
    "    Importance : C'est l'un des modèles les plus simples mais puissants pour la prédiction. La régression linéaire est souvent le premier modèle à essayer pour un problème de régression.\n",
    "    Pourquoi : Comprendre la régression linéaire vous aide à saisir les concepts de base comme le sur-ajustement, la régularisation, et les moindres carrés.\n",
    "\n",
    "4. Classification avec K-Nearest Neighbors (KNN)\n",
    "\n",
    "    Importance : KNN est un algorithme simple et intuitif pour la classification qui ne nécessite pas de modèle explicite.\n",
    "    Pourquoi : C’est un excellent point de départ pour comprendre les concepts de distance, de similarité, et d’apprentissage basé sur des exemples.\n",
    "\n",
    "5. Arbres de décision et Random Forests\n",
    "\n",
    "    Importance : Les arbres de décision sont faciles à comprendre et interpréter, et ils sont la base pour des modèles plus complexes comme les Random Forests et les Gradient Boosting Machines.\n",
    "    Pourquoi : Ils sont polyvalents et performants, surtout sur des données tabulaires. Leur compréhension permet de passer à des modèles d'ensemble plus avancés.\n",
    "\n",
    "6. Validation croisée et évaluation des modèles\n",
    "\n",
    "    Importance : Apprendre à évaluer correctement vos modèles est essentiel pour éviter le sur-ajustement et pour obtenir des résultats fiables.\n",
    "    Pourquoi : Les techniques comme la validation croisée permettent de tester la robustesse des modèles et de choisir le bon modèle.\n",
    "\n",
    "7. Les techniques de prétraitement des données\n",
    "\n",
    "    Importance : Le prétraitement des données (nettoyage, encodage, mise à l'échelle) est crucial pour préparer les données avant de les utiliser dans des modèles de machine learning.\n",
    "    Pourquoi : Les modèles performants nécessitent des données bien préparées. Apprendre ces techniques est donc fondamental.\n",
    "\n",
    "8. Les bibliothèques Python pour le machine learning\n",
    "\n",
    "    Importance : Familiarisez-vous avec des bibliothèques essentielles comme scikit-learn, pandas, et NumPy.\n",
    "    Pourquoi : Ces bibliothèques offrent des outils robustes et sont largement utilisées dans l'industrie et la recherche.\n",
    "\n",
    "9. Compréhension de la régularisation\n",
    "\n",
    "    Importance : Des techniques comme le Lasso (L1) et le Ridge (L2) sont cruciales pour prévenir le sur-ajustement et améliorer la généralisation des modèles.\n",
    "    Pourquoi : La régularisation est un concept clé dans la plupart des algorithmes de machine learning.\n",
    "\n",
    "10. Survol des algorithmes non supervisés\n",
    "\n",
    "    Importance : Comprendre des algorithmes comme K-means clustering et PCA (Principal Component Analysis) est utile pour l'exploration des données et la réduction de dimension.\n",
    "    Pourquoi : Ces techniques vous permettent de découvrir des structures cachées dans les données sans avoir besoin de labels.\n",
    "\n",
    "En vous concentrant sur ces sujets, vous couvrirez les concepts essentiels qui forment la base du machine learning, vous permettant ainsi de construire une base solide pour aller plus loin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## white noice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un exemple réel de bruit blanc dans le contexte des séries temporelles pourrait être les fluctuations quotidiennes des erreurs de mesure dans un capteur bien calibré. Imaginons un capteur de température ultra-précis utilisé dans un laboratoire pour surveiller une pièce dont la température est maintenue constante à 20°C.\n",
    "Contexte :\n",
    "\n",
    "Le capteur mesure la température toutes les heures et enregistre des valeurs très proches de 20°C, mais en raison de légères imperfections dans le capteur et de petites perturbations dans l'environnement (comme des micro-courants d'air ou des variations imperceptibles de la température), les mesures ne sont pas exactement identiques à chaque fois.\n",
    "Exemple de bruit blanc :\n",
    "\n",
    "Supposons que les mesures du capteur pour un jour donné soient les suivantes (en degrés Celsius) :\n",
    "\n",
    "- 20.1, 19.9, 20.0, 20.2, 19.8, 20.0, 19.9, 20.1, 20.0, 19.9, 20.1, 20.0, etc.\n",
    "\n",
    "Ces fluctuations sont petites, apparemment aléatoires, et ne suivent aucun motif identifiable.\n",
    "Caractéristiques de cette série temporelle :\n",
    "\n",
    "- Moyenne : Les mesures oscillent autour de la moyenne de 20°C, qui est la température réelle de la pièce.\n",
    "\n",
    "- Indépendance : Chaque mesure est indépendante de la précédente, car les perturbations sont dues à des facteurs aléatoires qui ne sont pas liés entre eux.\n",
    "\n",
    "- Variance constante : Les écarts autour de 20°C sont d'amplitude constante (par exemple, ±0,2°C), ce qui montre que la variance reste stable.\n",
    "\n",
    "Pourquoi c'est du bruit blanc ?\n",
    "\n",
    "- Les variations observées ne sont pas systématiques, mais plutôt aléatoires.\n",
    "- Il n'y a pas de tendance (les mesures ne montent ni ne descendent de façon prévisible).\n",
    "- Il n'y a pas de saisonnalité ou de cycle.\n",
    "- Les écarts ne sont corrélés ni avec les mesures précédentes ni avec les suivantes.\n",
    "\n",
    "Utilité de cet exemple :\n",
    "\n",
    "Dans cet exemple, les petites variations autour de 20°C représenteraient un \"bruit blanc\". Pour un ingénieur, reconnaître que ces variations constituent un bruit blanc permettrait de conclure que le capteur fonctionne correctement et que ces fluctuations sont simplement le résultat des erreurs de mesure inhérentes à tout instrument, plutôt que d'indiquer un problème avec le capteur ou l'environnement.\n",
    "\n",
    "Ainsi, ce \"bruit blanc\" dans les mesures peut être ignoré dans l'analyse, car il n'apporte aucune information sur un changement de température réel, ce qui permet de se concentrer sur des variations plus significatives qui pourraient indiquer un problème."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyther_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
